{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNdIvlVLnNj7MDqCIuPlLSV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NID123-CH/NLP--Hugging-Face-Project/blob/main/DSR_40_NLP_Language_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK4wikB0hUOm",
        "outputId": "e6a4a3bf-ed8b-4086-d7f9-a3becbe08381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.8.0 in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (24.3.25)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.11.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.64.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow==2.8.0\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras import models, layers\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Where the text files are going to live.\n",
        "dataset_path = \"dataset\"\n",
        "dataset_path_all = os.path.join(dataset_path, \"all\")\n",
        "dataset_path_train = os.path.join(dataset_path, \"train\")\n",
        "dataset_path_valid = os.path.join(dataset_path, \"valid\")\n",
        "\n",
        "# Just use 20 files.\n",
        "file_number = 20\n",
        "\n",
        "# Gather the corpus if it has not been gathered yet.\n",
        "if not os.path.exists(dataset_path):\n",
        "\n",
        "    # Create all the folders.\n",
        "    for path in [dataset_path, dataset_path_all, dataset_path_train, dataset_path_valid]:\n",
        "        if not os.path.exists(path):\n",
        "            os.mkdir(path)\n",
        "\n",
        "    # Clone the repo.\n",
        "    !git clone https://github.com/vilmibm/lovecraftcorpus\n",
        "\n",
        "    # Find all the files.\n",
        "    paths_all = glob.glob(\"lovecraftcorpus/*.txt\")\n",
        "    print(sorted(paths_all))\n",
        "\n",
        "    # Standardize.\n",
        "    for path in paths_all:\n",
        "        content = open(path).read()\n",
        "        content = content.lower()\n",
        "        for punctuation in \".,:;?!\":\n",
        "            content = content.replace(punctuation, \" \" + punctuation)\n",
        "        open(path, \"w\").write(content)\n",
        "\n",
        "    # Do not use all.\n",
        "    paths_all = paths_all[:file_number]\n",
        "\n",
        "    # Split 80/20.\n",
        "    split_index = int(len(paths_all) * 0.8)\n",
        "    paths_train = paths_all[:split_index]\n",
        "    paths_valid = paths_all[split_index:]\n",
        "\n",
        "    # Copy files.\n",
        "    def copy(paths, destination):\n",
        "        for path in paths:\n",
        "            shutil.copy2(path, destination)\n",
        "    copy(paths_all, dataset_path_all)\n",
        "    copy(paths_train, dataset_path_train)\n",
        "    copy(paths_valid, dataset_path_valid)\n",
        "\n",
        "    # Delete repo.\n",
        "    !rm -rf lovecraftcorpus\n",
        "\n",
        "    # Done.\n",
        "    print(\"Corpus downloaded.\")"
      ],
      "metadata": {
        "id": "IxtFaLXCiKnh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 # not for SGD\n",
        "seed = 42\n",
        "\n",
        "def create_dataset(dataset_path):\n",
        "    dataset = preprocessing.text_dataset_from_directory(\n",
        "        dataset_path,\n",
        "        labels=None,\n",
        "        batch_size=batch_size,\n",
        "        seed=seed\n",
        "    )\n",
        "    return dataset\n",
        "dataset_original_all = create_dataset(dataset_path_all)\n",
        "dataset_original_train = create_dataset(dataset_path_train)\n",
        "dataset_original_valid = create_dataset(dataset_path_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwTXk5shdvOO",
        "outputId": "dc1ed638-4b38-4096-ed25-a1202544bf1a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 files belonging to 1 classes.\n",
            "Found 16 files belonging to 1 classes.\n",
            "Found 4 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unravel it\n",
        "for x in dataset_original_all.take(1):\n",
        "    print(x.shape)\n",
        "    print(x[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkhfUeiicT_r",
        "outputId": "70dfc718-e2a3-4be9-899b-6d2957722f6f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20,)\n",
            "tf.Tensor(b'cool air\\n\\nyou ask me to explain why i am afraid of a draught of cool air ; why i shiver more than others upon entering a cold room , and seem nauseated and repelled when the chill of evening creeps through the heat of a mild autumn day . there are those who say i respond to cold as others do to a bad odour , and i am the last to deny the impression . what i will do is to relate the most horrible circumstance i ever encountered , and leave it to you to judge whether or not this forms a suitable explanation of my peculiarity .\\n\\nit is a mistake to fancy that horror is associated inextricably with darkness , silence , and solitude . i found it in the glare of mid-afternoon , in the clangour of a metropolis , and in the teeming midst of a shabby and commonplace rooming-house with a prosaic landlady and two stalwart men by my side . in the spring of 1923 i had secured some dreary and unprofitable magazine work in the city of new york ; and being unable to pay any substantial rent , began drifting from one cheap boarding establishment to another in search of a room which might combine the qualities of decent cleanliness , endurable furnishings , and very reasonable price . it soon developed that i had only a choice between different evils , but after a time i came upon a house in west fourteenth street which disgusted me much less than the others i had sampled .\\n\\nthe place was a four-story mansion of brownstone , dating apparently from the late forties , and fitted with woodwork and marble whose stained and sullied splendour argued a descent from high levels of tasteful opulence . in the rooms , large and lofty , and decorated with impossible paper and ridiculously ornate stucco cornices , there lingered a depressing mustiness and hint of obscure cookery ; but the floors were clean , the linen tolerably regular , and the hot water not too often cold or turned off , so that i came to regard it as at least a bearable place to hibernate till one might really live again . the landlady , a slatternly , almost bearded spanish woman named herrero , did not annoy me with gossip or with criticisms of the late-burning electric light in my third-floor front hall room ; and my fellow-lodgers were as quiet and uncommunicative as one might desire , being mostly spaniards a little above the coarsest and crudest grade . only the din of street cars in the thoroughfare below proved a serious annoyance .\\n\\ni had been there about three weeks when the first odd incident occurred . one evening at about eight i heard a spattering on the floor and became suddenly aware that i had been smelling the pungent odour of ammonia for some time . looking about , i saw that the ceiling was wet and dripping ; the soaking apparently proceeding from a corner on the side toward the street . anxious to stop the matter at its source , i hastened to the basement to tell the landlady ; and was assured by her that the trouble would quickly be set right .\\n\\n\"doctair mu\\xc3\\xb1oz ,\" she cried as she rushed upstairs ahead of me , \"he have speel hees chemicals . he ees too seeck for doctair heemself--seecker and seecker all the time--but he weel not have no othair for help . he ees vairy queer in hees seeckness--all day he take funnee--smelling baths , and he cannot get excite or warm . all hees own housework he do--hees leetle room are full of bottles and machines , and he do not work as doctair . but he was great once--my fathair in barcelona have hear of heem--and only joost now he feex a arm of the plumber that get hurt of sudden . he nevair go out , only on roof , and my boy esteban he breeng heem hees food and laundry and mediceens and chemicals . my gawd , the sal-ammoniac that man use for keep heem cool !\"\\n\\nmrs . herrero disappeared up the staircase to the fourth floor , and i returned to my room . the ammonia ceased to drip , and as i cleaned up what had spilled and opened the window for air , i heard the landlady\\'s heavy footsteps above me . dr . mu\\xc3\\xb1oz i had never heard , save for certain sounds as of some gasoline-driven mechanism ; since his step was soft and gentle . i wondered for a moment what the strange affliction of this man might be , and whether his obstinate refusal of outside aid were not the result of a rather baseless eccentricity . there is , i reflected tritely , an infinite deal of pathos in the state of an eminent person who has come down in the world .\\n\\ni might never have known dr . mu\\xc3\\xb1oz had it not been for the heart attack that suddenly seized me one forenoon as i sat writing in my room . physicians had told me of the danger of those spells , and i knew there was no time to be lost ; so remembering what the landlady had said about the invalid\\'s help of the injured workman , i dragged myself upstairs and knocked feebly at the door above mine . my knock was answered in good english by a curious voice some distance to the right , asking my name and business ; and these things being stated , there came an opening of the door next to the one i had sought .\\n\\na rush of cool air greeted me ; and though the day was one of the hottest of late june , i shivered as i crossed the threshold into a large apartment whose rich and tasteful decoration surprised me in this nest of squalor and seediness . a folding couch now filled its diurnal role of sofa , and the mahogany furniture , sumptuous hangings , old paintings , and mellow bookshelves all bespoke a gentleman\\'s study rather than a boarding-house bedroom . i now saw that the hall room above mine--the \"leetle room\" of bottles and machines which mrs . herrero had mentioned was merely the laboratory of the doctor ; and that his main living quarters lay in the spacious adjoining room whose convenient alcoves and large contiguous bathroom permitted him to hide all dressers and obtrusively utilitarian devices . dr . mu\\xc3\\xb1oz , most certainly , was a man of birth , cultivation , and discrimination .\\n\\nthe figure before me was short but exquisitely proportioned , and clad in somewhat formal dress of perfect cut and fit . a high-bred face of masterful though not arrogant expression was adorned by a short iron--grey full beard , and an old-fashioned pince-nez shielded the full , dark eyes and surmounted an aquiline nose which gave a moorish touch to a physiognomy otherwise dominantly celtiberian . thick , well-trimmed hair that argued the punctual calls of a barber was parted gracefully above a high forehead ; and the whole picture was one of striking intelligence and superior blood and breeding .\\n\\nnevertheless , as i saw dr . mu\\xc3\\xb1oz in that blast of cool air , i felt a repugnance which nothing in his aspect could justify . only his lividly inclined complexion and coldness of touch could have afforded a physical basis for this feeling , and even these things should have been excusable considering the man\\'s known invalidism . it might , too , have been the singular cold that alienated me ; for such chilliness was abnormal on so hot a day , and the abnormal always excites aversion , distrust , and fear .\\n\\nbut repugnance was soon forgotten in admiration , for the strange physician\\'s extreme skill at once became manifest despite the ice-coldness and shakiness of his bloodless-looking hands . he clearly understood my needs at a glance , and ministered to them with a master\\'s deftness ; the while reassuring me in a finely modulated though oddly hollow and timbreless voice that he was the bitterest of sworn enemies to death , and had sunk his fortune and lost all his friends in a lifetime of bizarre experiment devoted to its bafflement and extirpation . something of the benevolent fanatic seemed to reside in him , and he rambled on almost garrulously as he sounded my chest and mixed a suitable draught of drugs fetched from the smaller laboratory room . evidently he found the society of a well-born man a rare novelty in this dingy environment , and was moved to unaccustomed speech as memories of better days surged over him .\\n\\nhis voice , if queer , was at least soothing ; and i could not even perceive that he breathed as the fluent sentences rolled urbanely out . he sought to distract my mind from my own seizure by speaking of his theories and experiments ; and i remember his tactfully consoling me about my weak heart by insisting that will and consciousness are stronger than organic life itself , so that if a bodily frame be but originally healthy and carefully preserved , it may through a scientific enhancement of these qualities retain a kind of nervous animation despite the most serious impairments , defects , or even absences in the battery of specific organs . he might , he half jestingly said , some day teach me to live--or at least to possess some kind of conscious existence--without any heart at all ! for his part , he was afflicted with a complication of maladies requiring a very exact regimen which included constant cold . any marked rise in temperature might , if prolonged , affect him fatally ; and the frigidity of his habitation--some 55 or 56 degrees fahrenheit--was maintained by an absorption system of ammonia cooling , the gasoline engine of whose pumps i had often heard in my own room below .\\n\\nrelieved of my seizure in a marvellously short while , i left the shivery place a disciple and devotee of the gifted recluse . after that i paid him frequent overcoated calls ; listening while he told of secret researches and almost ghastly results , and trembling a bit when i examined the unconventional and astonishingly ancient volumes on his shelves . i was eventually , i may add , almost cured of my disease for all time by his skillful ministrations . it seems that he did not scorn the incantations of the mediaevalists , since he believed these cryptic formulae to contain rare psychological stimuli which might conceivably have singular effects on the substance of a nervous system from which organic pulsations had fled . i was touched by his account of the aged dr . torres of valencia , who had shared his earlier experiments and nursed him through the great illness of eighteen years before , whence his present disorders proceeded . no sooner had the venerable practitioner saved his colleague than he himself succumbed to the grim enemy he had fought . perhaps the strain had been too great ; for dr . mu\\xc3\\xb1oz made it whisperingly clear--though not in detail--that the methods of healing had been most extraordinary , involving scenes and processes not welcomed by elderly and conservative galens .\\n\\nas the weeks passed , i observed with regret that my new friend was indeed slowly but unmistakably losing ground physically , as mrs . herrero had suggested . the livid aspect of his countenance was intensified , his voice became more hollow and indistinct , his muscular motions were less perfectly coordinated , and his mind and will displayed less resilience and initiative . of this sad change he seemed by no means unaware , and little by little his expression and conversation both took on a gruesome irony which restored in me something of the subtle repulsion i had originally felt .\\n\\nhe developed strange caprices , acquiring a fondness for exotic spices and egyptian incense till his room smelled like a vault of a sepulchred pharaoh in the valley of kings . at the same time his demands for cold air increased , and with my aid he amplified the ammonia piping of his room and modified the pumps and feed of his refrigerating machine till he could keep the temperature as low as 34 degrees or 40 degrees , and finally even 28 degrees ; the bathroom and laboratory , of course , being less chilled , in order that water might not freeze , and that chemical processes might not be impeded . the tenant adjoining him complained of the icy air from around the connecting door , so i helped him fit heavy hangings to obviate the difficulty . a kind of growing horror , of outre and morbid cast , seemed to possess him . he talked of death incessantly , but laughed hollowly when such things as burial or funeral arrangements were gently suggested .\\n\\nall in all , he became a disconcerting and even gruesome companion ; yet in my gratitude for his healing i could not well abandon him to the strangers around him , and was careful to dust his room and attend to his needs each day , muffled in a heavy ulster which i bought especially for the purpose . i likewise did much of his shopping , and gasped in bafflement at some of the chemicals he ordered from druggists and laboratory supply houses .\\n\\nan increasing and unexplained atmosphere of panic seemed to rise around his apartment . the whole house , as i have said , had a musty odour ; but the smell in his room was worse--and in spite of all the spices and incense , and the pungent chemicals of the now incessant baths which he insisted on taking unaided . i perceived that it must be connected with his ailment , and shuddered when i reflected on what that ailment might be . mrs . herrero crossed herself when she looked at him , and gave him up unreservedly to me ; not even letting her son esteban continue to run errands for him . when i suggested other physicians , the sufferer would fly into as much of a rage as he seemed to dare to entertain . he evidently feared the physical effect of violent emotion , yet his will and driving force waxed rather than waned , and he refused to be confined to his bed . the lassitude of his earlier ill days gave place to a return of his fiery purpose , so that he seemed about to hurl defiance at the death-daemon even as that ancient enemy seized him . the pretence of eating , always curiously like a formality with him , he virtually abandoned ; and mental power alone appeared to keep him from total collapse .\\n\\nhe acquired a habit of writing long documents of some sort , which he carefully sealed and filled with injunctions that i transmit them after his death to certain persons whom he named--for the most part lettered east indians , but including a once celebrated french physician now generally thought dead , and about whom the most inconceivable things had been whispered . as it happened , i burned all these papers undelivered and unopened . his aspect and voice became utterly frightful , and his presence almost unbearable . one september day an unexpected glimpse of him induced an epileptic fit in a man who had come to repair his electric desk lamp ; a fit for which he prescribed effectively whilst keeping himself well out of sight . that man , oddly enough , had been through the terrors of the great war without having incurred any fright so thorough .\\n\\nthen , in the middle of october , the horror of horrors came with stupefying suddenness . one night about eleven the pump of the refrigerating machine broke down , so that within three hours the process of ammonia cooling became impossible . dr . mu\\xc3\\xb1oz summoned me by thumping on the floor , and i worked desperately to repair the injury while my host cursed in a tone whose lifeless , rattling hollowness surpassed description . my amateur efforts , however , proved of no use ; and when i had brought in a mechanic from a neighbouring all-night garage , we learned that nothing could be done till morning , when a new piston would have to be obtained . the moribund hermit\\'s rage and fear , swelling to grotesque proportions , seemed likely to shatter what remained of his failing physique , and once a spasm caused him to clap his hands to his eyes and rush into the bathroom . he groped his way out with face tightly bandaged , and i never saw his eyes again .\\n\\nthe frigidity of the apartment was now sensibly diminishing , and at about 5 a .m . the doctor retired to the bathroom , commanding me to keep him supplied with all the ice i could obtain at all-night drug stores and cafeterias . as i would return from my sometimes discouraging trips and lay my spoils before the closed bathroom door , i could hear a restless splashing within , and a thick voice croaking out the order for \"more--more !\" at length a warm day broke , and the shops opened one by one . i asked esteban either to help with the ice-fetching whilst i obtained the pump piston , or to order the piston while i continued with the ice ; but instructed by his mother , he absolutely refused .\\n\\nfinally i hired a seedy-looking loafer whom i encountered on the corner of eighth avenue to keep the patient supplied with ice from a little shop where i introduced him , and applied myself diligently to the task of finding a pump piston and engaging workmen competent to install it . the task seemed interminable , and i raged almost as violently as the hermit when i saw the hours slipping by in a breathless , foodless round of vain telephoning , and a hectic quest from place to place , hither and thither by subway and surface car . about noon i encountered a suitable supply house far downtown , and at approximately 1 :30 p .m . arrived at my boarding-place with the necessary paraphernalia and two sturdy and intelligent mechanics . i had done all i could , and hoped i was in time .\\n\\nblack terror , however , had preceded me . the house was in utter turmoil , and above the chatter of awed voices i heard a man praying in a deep basso . fiendish things were in the air , and lodgers told over the beads of their rosaries as they caught the odour from beneath the doctor\\'s closed door . the lounger i had hired , it seems , had fled screaming and mad-eyed not long after his second delivery of ice ; perhaps as a result of excessive curiosity . he could not , of course , have locked the door behind him ; yet it was now fastened , presumably from the inside . there was no sound within save a nameless sort of slow , thick dripping .\\n\\nbriefly consulting with mrs . herrero and the workmen despite a fear that gnawed my inmost soul , i advised the breaking down of the door ; but the landlady found a way to turn the key from the outside with some wire device . we had previously opened the doors of all the other rooms on that hall , and flung all the windows to the very top . now , noses protected by handkerchiefs , we tremblingly invaded the accursed south room which blazed with the warm sun of early afternoon .\\n\\na kind of dark , slimy trail led from the open bathroom door to the hall door , and thence to the desk , where a terrible little pool had accumulated . something was scrawled there in pencil in an awful , blind hand on a piece of paper hideously smeared as though by the very claws that traced the hurried last words . then the trail led to the couch and ended unutterably .\\n\\nwhat was , or had been , on the couch i cannot and dare not say here . but this is what i shiveringly puzzled out on the stickily smeared paper before i drew a match and burned it to a crisp ; what i puzzled out in terror as the landlady and two mechanics rushed frantically from that hellish place to babble their incoherent stories at the nearest police station . the nauseous words seemed well-nigh incredible in that yellow sunlight , with the clatter of cars and motor trucks ascending clamorously from crowded fourteenth street , yet i confess that i believed them then . whether i believe them now i honestly do not know . there are things about which it is better not to speculate , and all that i can say is that i hate the smell of ammonia , and grow faint at a draught of unusually cool air .\\n\\n\"the end ,\" ran that noisome scrawl , \"is here . no more ice--the man looked and ran away . warmer every minute , and the tissues can\\'t last . i fancy you know what i said about the will and the nerves and the preserved body after the organs ceased to work . it was good theory , but couldn\\'t keep up indefinitely . there was a gradual deterioration i had not foreseen . dr . torres knew , but the shock killed him . he couldn\\'t stand what he had to do--he had to get me in a strange , dark place when he minded my letter and nursed me back . and the organs never would work again . it had to be done my way--preservation--for you see i died that time eighteen years ago .\"\\n', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = 10_000\n",
        "\n",
        "encoder = layers.TextVectorization(\n",
        "    max_tokens=vocabulary_size,\n",
        "    standardize=None, # keep the punctuation\n",
        "    split='whitespace',\n",
        "    output_mode='int'\n",
        ")\n",
        "\n",
        "encoder.adapt(dataset_original_all)\n",
        "vocabulary = encoder.get_vocabulary()\n",
        "print(vocabulary[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fitM5_gkicwg",
        "outputId": "dd32e74a-232b-40fa-b710-049729974573"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', 'the', ',', 'and', '.', 'of', 'a', 'to', 'in', 'was', 'that', 'i', 'he', 'had', 'it', 'his', 'as', 'with', 'on', ';', 'at', 'from', 'for', 'but', 'which', 'not', 'were', 'they', 'my']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 32 # tiny neural network\n",
        "padding_token_id = 0\n",
        "\n",
        "def create_dataset_for_autoregression(dataset, hop_length=1):\n",
        "    x_inputs = []\n",
        "    y_outputs = []\n",
        "\n",
        "    for books in dataset:\n",
        "        books = encoder(books).numpy()\n",
        "        for book in books:\n",
        "\n",
        "            #remove padding tokens\n",
        "            book = [index for index in list(book) if index != padding_token_id]\n",
        "\n",
        "            for start_index in range(0, len(book)-sequence_length, hop_length):\n",
        "                x = book[start_index:start_index + sequence_length]\n",
        "                y = book[start_index +1: start_index + sequence_length + 1]\n",
        "                assert len(x) == sequence_length\n",
        "                assert len(y) == sequence_length\n",
        "\n",
        "                # The assert False statement was causing the error. It has been removed.\n",
        "\n",
        "                x_inputs += [x]\n",
        "                y_outputs += [y] # typo here, it was y_inputs\n",
        "\n",
        "\n",
        "\n",
        "        #assert False # This assert False statement was causing the error. It has been removed.\n",
        "\n",
        "\n",
        "    return tf.data.Dataset.from_tensor_slices((x_inputs, y_outputs))\n",
        "dataset_train = create_dataset_for_autoregression(dataset_original_train)\n",
        "dataset_valid = create_dataset_for_autoregression(dataset_original_valid)"
      ],
      "metadata": {
        "id": "w-X0U5fvgey4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(indices):\n",
        "  return \" \".join([vocabulary[index]for index in indices])\n",
        "\n",
        "for input,output in dataset_train.take(8):\n",
        "    print(\"in: \", decode(input))\n",
        "    print(\"out: \",decode(output))\n",
        "    print(\"\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaBNkbUSh_GD",
        "outputId": "540e1150-643b-468f-93ec-4e9c020d9c07"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in:  the white ship i am [UNK] elton , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse ,\n",
            "out:  white ship i am [UNK] elton , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above\n",
            "\n",
            "in:  white ship i am [UNK] elton , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above\n",
            "out:  ship i am [UNK] elton , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above sunken\n",
            "\n",
            "in:  ship i am [UNK] elton , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above sunken\n",
            "out:  i am [UNK] elton , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above sunken slimy\n",
            "\n",
            "in:  i am [UNK] elton , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above sunken slimy\n",
            "out:  am [UNK] elton , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above sunken slimy rocks\n",
            "\n",
            "in:  am [UNK] elton , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above sunken slimy rocks\n",
            "out:  [UNK] elton , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above sunken slimy rocks that\n",
            "\n",
            "in:  [UNK] elton , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above sunken slimy rocks that\n",
            "out:  elton , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above sunken slimy rocks that are\n",
            "\n",
            "in:  elton , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above sunken slimy rocks that are\n",
            "out:  , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above sunken slimy rocks that are seen\n",
            "\n",
            "in:  , keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above sunken slimy rocks that are seen\n",
            "out:  keeper of the north point light that my father and grandfather kept before me . far from the shore stands the gray lighthouse , above sunken slimy rocks that are seen when\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def render_history(history):\n",
        "    plt.title(\"Training loss vs. validation loss\")\n",
        "    plt.plot(history.history[\"loss\"], label=\"loss\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    plt.title(\"Training accuracy vs. validation accuracy\")\n",
        "    plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
        "    plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "0NWY-eK9krDg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model**"
      ],
      "metadata": {
        "id": "Oz7OrUPdmhZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 128\n",
        "\n",
        "model= models.Sequential()\n",
        "model.add(layers.Embedding(vocabulary_size, embedding_size, input_length=sequence_length))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.LSTM(embedding_size, return_sequences=True))\n",
        "model.add(layers.Dropout(0.1))\n",
        "model.add(layers.Dense(vocabulary_size, activation=\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    dataset_train.shuffle(10_000).batch(1024),\n",
        "    validation_data=dataset_valid.batch(1024),\n",
        "    epochs=2,\n",
        "\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iORwQxPimPa-",
        "outputId": "0d77f1e4-3c1f-4b06-97d8-b0e187b07c5d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 32, 128)           1280000   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 128)           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32, 128)           131584    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32, 128)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32, 10000)         1290000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,701,584\n",
            "Trainable params: 2,701,584\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "66/66 [==============================] - 1307s 20s/step - loss: 7.5939 - accuracy: 0.0484 - val_loss: 7.0592 - val_accuracy: 0.0686\n",
            "Epoch 2/2\n",
            "66/66 [==============================] - 1296s 20s/step - loss: 6.7104 - accuracy: 0.0657 - val_loss: 7.0622 - val_accuracy: 0.0686\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a7738bcf430>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, seed_text, generated_sequence_length, temperature):\n",
        "\n",
        "    seed_text = seed_text.lower()\n",
        "    for punctuation in \".,:;?!\":\n",
        "        seed_text = seed_text.replace(punctuation, \" \" + punctuation)\n",
        "    print(\"Seed text: \" + seed_text)\n",
        "\n",
        "\n",
        "    input_sequence = encoder(seed_text).numpy().tolist()\n",
        "    print(input_sequence)\n",
        "\n",
        "    # Generate the sequence by repeatedly predicting.\n",
        "    while len(input_sequence) < generated_sequence_length:\n",
        "        prediction = model.predict(np.expand_dims(input_sequence, axis=0), verbose=False)\n",
        "        predicted_index = get_index_from_prediction(prediction[0][-1], temperature)\n",
        "        input_sequence.append(predicted_index)\n",
        "\n",
        "    # Convert the generated sequence to a string.\n",
        "    text = decode(input_sequence)\n",
        "    for punctuation in \".,:;?!\":\n",
        "        text = text.replace(\" \" + punctuation, punctuation)\n",
        "    print(text)\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "def get_index_from_prediction(prediction, temperature=0.0):\n",
        "    \"\"\" Gets an index from a prediction. \"\"\"\n",
        "\n",
        "    # Zero temperature - use the argmax.\n",
        "    if temperature == 0.0:\n",
        "        return np.argmax(prediction)\n",
        "\n",
        "    # Non-zero temperature - do some random magic.\n",
        "    else:\n",
        "        prediction = np.asarray(prediction).astype('float64')\n",
        "        prediction = np.log(prediction) / temperature\n",
        "        exp_prediction= np.exp(prediction)\n",
        "        prediction = exp_prediction / np.sum(exp_prediction)\n",
        "        probabilities = np.random.multinomial(1, prediction, 1)\n",
        "        return np.argmax(probabilities)\n"
      ],
      "metadata": {
        "id": "OrOwl_BP1rut"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_"
      ],
      "metadata": {
        "id": "dBvttMdt6SBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}